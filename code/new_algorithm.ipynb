{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4600d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cnf import CNF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c3202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9317f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin = nn.Linear(3, 5)\n",
    "        self.lin.weight.data.uniform_(0,0.01)\n",
    "        self.lin.bias.data.uniform_(0,0.001)\n",
    "        self.lin2 = nn.Linear(5, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f8c8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dir(path):\n",
    "    data = []\n",
    "    for filename in os.listdir(path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext != '.cnf':\n",
    "            continue\n",
    "        f = CNF.from_file(os.path.join(path, filename))\n",
    "        data.append(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae962f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_variable_reinforce(x, policy):\n",
    "    logit = policy(x)\n",
    "    prob = F.softmax(logit, dim=0)\n",
    "    dist = Categorical(prob.view(-1))\n",
    "    v = dist.sample()\n",
    "    return v, dist.log_prob(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa233370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_true_lit_count(clauses, sol):\n",
    "    n_clauses = len(clauses)\n",
    "    true_lit_count = [0] * n_clauses\n",
    "    for i in range(n_clauses):\n",
    "        for lit in clauses[i]:\n",
    "            if sol[abs(lit)] == lit:\n",
    "                true_lit_count[i] += 1\n",
    "    return true_lit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d4c9ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_flip(sol, true_lit_count, v, occur_list):\n",
    "    sol[v + 1] *= -1\n",
    "    literal = sol[v + 1]\n",
    "    for i in occur_list[literal]:\n",
    "        true_lit_count[i] += 1\n",
    "    for i in occur_list[-literal]:\n",
    "        true_lit_count[i] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d275a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs to be more efficient\n",
    "# consider a subset of the unsat clauses\n",
    "def stats(f, sol, last_10, last_5, true_lit_count):\n",
    "    \"\"\" computes the featutes needed for the model\n",
    "    \"\"\"\n",
    "    r = f.n_variables/ len(f.clauses)\n",
    "    breaks = np.zeros(f.n_variables)\n",
    "    for v in range(1, len(sol)):\n",
    "        broken_count = 0\n",
    "        literal = sol[v]\n",
    "        for index in f.occur_list[-literal]:\n",
    "            if true_lit_count[index] == 1:\n",
    "                broken_count += 1\n",
    "        breaks[v - 1] = r*broken_count\n",
    "    in_last_10 = np.array([int(i + 1 in last_10) for i in range(f.n_variables)]) \n",
    "    in_last_5 = np.array([int(i + 1 in last_5) for i in range(f.n_variables)]) \n",
    "    return np.stack([breaks, in_last_10, in_last_5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "670d1534",
   "metadata": {},
   "outputs": [],
   "source": [
    " def generate_episode_reinforce(f, policy, max_flips, walk_prob):\n",
    "    sol = [x if random.random() < 0.5 else -x for x in range(f.n_variables + 1)]\n",
    "    true_lit_count = compute_true_lit_count(f.clauses, sol)\n",
    "    log_probs = []\n",
    "    flips = 0\n",
    "    flipped = set()\n",
    "    backflipped = 0\n",
    "    unsat_clauses = []\n",
    "    last_10 = [0]*10\n",
    "    last_5 = []\n",
    "    while flips < max_flips:\n",
    "        unsat_clause_indices = [k for k in range(len(f.clauses)) if true_lit_count[k] == 0]\n",
    "        unsat_clauses.append(len(unsat_clause_indices))\n",
    "        sat = not unsat_clause_indices\n",
    "        if sat:\n",
    "            break\n",
    "        if random.random() < walk_prob:\n",
    "            unsat_clause = f.clauses[random.choice(unsat_clause_indices)]\n",
    "            v, log_prob = abs(random.choice(unsat_clause)) - 1, None\n",
    "        else:\n",
    "            x = stats(f, sol, last_10, last_5, true_lit_count)\n",
    "            x = torch.from_numpy(x).float()\n",
    "            v, log_prob = select_variable_reinforce(x, policy)\n",
    "            if v.item() not in flipped:\n",
    "                flipped.add(v.item())\n",
    "                last_10.insert(0, v.item() + 1)\n",
    "                last_10 = last_10[:10]\n",
    "                last_5 = last_10[:5]\n",
    "            else:\n",
    "                backflipped += 1\n",
    "        do_flip(sol, true_lit_count, v, f.occur_list)\n",
    "        flips += 1\n",
    "        log_probs.append(log_prob)\n",
    "    return sat, (flips, backflipped, unsat_clauses), (log_probs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "287bfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_loss(history, discount):\n",
    "    log_probs_list = history[0]\n",
    "    T = len(log_probs_list)\n",
    "    log_probs_filtered = []\n",
    "    mask = np.zeros(T, dtype=bool)\n",
    "    for i, x in enumerate(log_probs_list):\n",
    "        if x is not None:\n",
    "            log_probs_filtered.append(x)\n",
    "            mask[i] = 1\n",
    "\n",
    "    log_probs = torch.stack(log_probs_filtered)\n",
    "    partial_rewards = discount ** torch.arange(T - 1, -1, -1, dtype=torch.float32, device=log_probs.device)\n",
    "    return -torch.mean(partial_rewards[torch.from_numpy(mask).to(log_probs.device)] * log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a6edb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episodes(policy, f, max_fries, max_flips, discount, walk_prob=.5):\n",
    "    flips_stats = []\n",
    "    losses = []\n",
    "    backflips = []\n",
    "    num_sols = 0\n",
    "    for i in range(max_tries):\n",
    "        out = generate_episode_reinforce(f, policy, max_flips=max_flips, walk_prob=walk_prob)\n",
    "        sat, (flips, backflipped, unsat_clauses), history = out\n",
    "    \n",
    "        flips_stats.append(flips)\n",
    "        backflips.append(backflipped)\n",
    "        if sat and flips > 0 and not all(map(lambda x: x is None, history[0])):\n",
    "            loss = reinforce_loss(history, discount)\n",
    "            losses.append(loss)\n",
    "        num_sols += sat    \n",
    "    if losses:\n",
    "        losses = torch.stack(losses).sum()  \n",
    "    return np.mean(flips), np.mean(backflips), losses, num_sols/max_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a17e70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy, data, max_tries, max_flips, discount, walk_prob=.5):\n",
    "    mean_flips = []\n",
    "    mean_backflips = []\n",
    "    mean_losses = []\n",
    "    accuracy = []\n",
    "    policy.eval()\n",
    "    for f in data:\n",
    "        flips, backflips, losses, acc = generate_episodes(policy, f, max_tries, max_flips, discount,\n",
    "                                                          walk_prob)\n",
    "        mean_flips.append(flips)\n",
    "        mean_backflips.append(backflips)\n",
    "        if losses:\n",
    "            mean_losses.append(losses.item())\n",
    "        accuracy.append(acc)\n",
    "    print(np.mean(mean_flips), np.mean(mean_backflips), np.mean(mean_losses), np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(policy, optimizer, data, max_tries = 10, max_flips = 10000, discount = 0.5, walk_prob=.5):\n",
    "    losses = []\n",
    "    for f in data:\n",
    "        policy.train()\n",
    "        flips, backflips, loss, acc = generate_episodes(policy, f, max_tries, max_flips, discount, walk_prob)\n",
    "        if acc > 0:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a44e2fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = load_dir(\"../data/rand3sat/10-43\")\n",
    "val_ds = load_dir(\"../data/rand3sat/25-106\")\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c8d3cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_lr(optimizer, lr):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d5c035a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Net()\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "max_tries = 10\n",
    "max_flips = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    evaluate(policy, val_ds[:100] , max_tries, max_flips, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch(policy, optimizer, train_ds[:500], walk_prob=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad383189",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    evaluate(policy, val_ds[:100] , max_tries, max_flips, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch(policy, optimizer, train_ds[500:1000], walk_prob=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f47b8486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.8 28.726 1.7562458352930843 1.0\n",
      "68.1 31.000999999999994 1.6202993234992027 1.0\n",
      "69.8 27.831999999999997 1.511616210155189 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    evaluate(policy, val_ds[:100] , max_tries, max_flips, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ea010241",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_lr(optimizer, 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2905824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.3106,  0.2155,  0.2198],\n",
      "        [-0.3193,  0.2277,  0.2245],\n",
      "        [ 0.7599, -0.1529, -0.1491],\n",
      "        [ 0.7396, -0.1564, -0.1603],\n",
      "        [ 0.7672, -0.1613, -0.1648]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3773, 0.3879, 0.3021, 0.3200, 0.3262], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.0492, -0.8462,  0.9129,  1.1484,  0.9808]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0013], requires_grad=True)]\n",
      "[Parameter containing:\n",
      "tensor([[-0.4077,  0.2480,  0.2523],\n",
      "        [-0.4169,  0.2604,  0.2572],\n",
      "        [ 1.0000, -0.1836, -0.1797],\n",
      "        [ 0.9783, -0.1869, -0.1909],\n",
      "        [ 1.0068, -0.1919, -0.1953]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4781, 0.4899, 0.3548, 0.3693, 0.3788], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.2844, -1.0807,  1.1638,  1.3998,  1.2319]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0009], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "train_epoch(policy, optimizer, train_ds[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7492db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.54 29.662000000000003 1.3064033984579146 1.0\n",
      "73.82 27.777 1.1989874884858727 1.0\n",
      "119.43 30.728999999999996 1.2746308460831641 1.0\n",
      "64.36 30.643999999999995 1.2890113532729446 1.0\n",
      "77.1 28.85 1.3198073209263383 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    evaluate(policy, val_ds[:100], max_tries, max_flips, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb2c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
