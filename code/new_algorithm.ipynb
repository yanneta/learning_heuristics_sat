{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4600d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cnf import CNF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c3202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9317f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, h=5):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin = nn.Linear(3, h)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.lin2 = nn.Linear(h, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = F.relu(self.dropout(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe48a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net(model):\n",
    "    with torch.no_grad():\n",
    "        model.lin.weight[0, 0] = 10\n",
    "        model.lin2.weight[0, 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9275b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.lin = nn.Linear(3, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3aa19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net2(policy):\n",
    "    with torch.no_grad():\n",
    "        policy.lin.weight[0, 0] = -1\n",
    "        policy.lin.weight[0, 1] = 0\n",
    "        policy.lin.weight[0, 2] = 0\n",
    "        policy.lin.bias[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f8c8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dir(path):\n",
    "    data = []\n",
    "    for filename in os.listdir(path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext != '.cnf':\n",
    "            continue\n",
    "        f = CNF.from_file(os.path.join(path, filename))\n",
    "        data.append(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feaca9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalkSATLN:\n",
    "    def __init__(self, policy, max_tries, max_flips, p=0.5, discount=0.5):\n",
    "        self.policy = policy\n",
    "        self.max_tries = max_tries\n",
    "        self.max_flips = max_flips\n",
    "        self.p = p\n",
    "        self.discount = discount\n",
    "        self.flips_to_solution = []\n",
    "        self.backflips = []\n",
    "        self.unsat_clauses = []\n",
    "        self.age = []\n",
    "        self.last_10 = []\n",
    "        self.sol = []\n",
    "        \n",
    "    def compute_true_lit_count(self, clauses):\n",
    "        n_clauses = len(clauses)\n",
    "        true_lit_count = [0] * n_clauses\n",
    "        for index in range(n_clauses):\n",
    "            for literal in clauses[index]:\n",
    "                if self.sol[abs(literal)] == literal:\n",
    "                    true_lit_count[index] += 1\n",
    "        return true_lit_count\n",
    "    \n",
    "    def select_variable_reinforce(self, x):\n",
    "        logit = self.policy(x)\n",
    "        prob = F.softmax(logit, dim=0)\n",
    "        dist = Categorical(prob.view(-1))\n",
    "        v = dist.sample()\n",
    "        return v, dist.log_prob(v)\n",
    "    \n",
    "    def do_flip(self, literal, occur_list):\n",
    "        for i in occur_list[literal]:\n",
    "            self.true_lit_count[i] += 1\n",
    "        for i in occur_list[-literal]:\n",
    "            self.true_lit_count[i] -= 1\n",
    "        self.sol[abs(literal)] *= -1\n",
    "        \n",
    "    def stats_per_clause(self, f, unsat_clause):\n",
    "        \"\"\" computes the featutes needed for the model\n",
    "        \"\"\" \n",
    "        r = f.n_variables/ len(f.clauses)\n",
    "        variables = [abs(v) for v in unsat_clause]\n",
    "        breaks = np.zeros(len(variables))\n",
    "        last_5 = self.last_10[:5]\n",
    "        for i, literal in enumerate(unsat_clause):\n",
    "            broken_count = 0\n",
    "            for index in f.occur_list[-literal]:\n",
    "                if self.true_lit_count[index] == 1:\n",
    "                    broken_count += 1\n",
    "            breaks[i] = broken_count\n",
    "        in_last_10 = np.array([int(i + 1 in self.last_10) for i in variables]) \n",
    "        in_last_5 = np.array([int(i + 1 in last_5) for i in variables]) \n",
    "        return np.stack([breaks, in_last_10, in_last_5], axis=1)\n",
    "    \n",
    "    def walksat_step(self, f, unsat_clause):\n",
    "        \"\"\"Returns chosen literal\"\"\"\n",
    "        broken_min = float('inf')\n",
    "        min_breaking_lits = []\n",
    "        for literal in unsat_clause:\n",
    "            broken_count = 0\n",
    "            for index in f.occur_list[-literal]:\n",
    "                if self.true_lit_count[index] == 1:\n",
    "                    broken_count += 1\n",
    "                if broken_count > broken_min:\n",
    "                    break\n",
    "            if broken_count < broken_min:\n",
    "                broken_min = broken_count\n",
    "                min_breaking_lits = [literal]\n",
    "            elif broken_count == broken_min:\n",
    "                min_breaking_lits.append(literal)\n",
    "        return abs(random.choice(min_breaking_lits))\n",
    "    \n",
    "    def reinforce_step(self, f, unsat_clause):\n",
    "        x = self.stats_per_clause(f, unsat_clause)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        index, log_prob = self.select_variable_reinforce(x)\n",
    "        literal = unsat_clause[index]\n",
    "        return literal, log_prob\n",
    "    \n",
    "    def generate_episode_reinforce(self, f, walksat):\n",
    "        self.sol = [x if random.random() < 0.5 else -x for x in range(f.n_variables + 1)]\n",
    "        self.true_lit_count = self.compute_true_lit_count(f.clauses)\n",
    "        log_probs = []\n",
    "        flips = 0\n",
    "        flipped = set()\n",
    "        backflipped = 0\n",
    "        while flips < max_flips:\n",
    "            unsat_clause_indices = [k for k in range(len(f.clauses)) if self.true_lit_count[k] == 0]\n",
    "            sat = not unsat_clause_indices\n",
    "            if sat:\n",
    "                break\n",
    "            unsat_clause = f.clauses[random.choice(unsat_clause_indices)]\n",
    "            log_prob = None\n",
    "            if random.random() < self.p:\n",
    "                literal = random.choice(unsat_clause)\n",
    "            else:\n",
    "                if walksat:\n",
    "                    literal = self.walksat_step(f, unsat_clause)   \n",
    "                else:\n",
    "                    literal, log_prob = self.reinforce_step(f, unsat_clause)\n",
    "                v = abs(literal)\n",
    "                if v not in flipped:\n",
    "                    flipped.add(v)\n",
    "                else:\n",
    "                    backflipped += 1\n",
    "                self.last_10.insert(0, v)\n",
    "                self.last_10 = self.last_10[:10]\n",
    "            self.do_flip(literal, f.occur_list)\n",
    "            flips += 1\n",
    "            log_probs.append(log_prob)\n",
    "        return sat, flips, backflipped, log_probs\n",
    "\n",
    "    def reinforce_loss(self, log_probs_list):\n",
    "        T = len(log_probs_list)\n",
    "        log_probs_filtered = []\n",
    "        mask = np.zeros(T, dtype=bool)\n",
    "        for i, x in enumerate(log_probs_list):\n",
    "            if x is not None:\n",
    "                log_probs_filtered.append(x)\n",
    "                mask[i] = 1\n",
    "\n",
    "        log_probs = torch.stack(log_probs_filtered)\n",
    "        p_rewards = self.discount ** torch.arange(T - 1, -1, -1, dtype=torch.float32, device=log_probs.device)\n",
    "        return -torch.mean(p_rewards[torch.from_numpy(mask).to(log_probs.device)] * log_probs)\n",
    "\n",
    "    def generate_episodes(self, f, walksat=False):\n",
    "        flips_stats = []\n",
    "        losses = []\n",
    "        backflips = []\n",
    "        num_sols = 0\n",
    "        for i in range(self.max_tries):\n",
    "            sat, flips, backflipped, log_probs = self.generate_episode_reinforce(f, walksat)\n",
    "            flips_stats.append(flips)\n",
    "            backflips.append(backflipped)\n",
    "            if sat and flips > 0 and not all(map(lambda x: x is None, log_probs)):\n",
    "                loss = self.reinforce_loss(log_probs)\n",
    "                losses.append(loss)\n",
    "            num_sols += sat    \n",
    "        if losses:\n",
    "            losses = torch.stack(losses).sum()  \n",
    "        return np.mean(flips), np.mean(backflips), losses, num_sols/self.max_tries\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, walksat=False):\n",
    "        mean_flips = []\n",
    "        mean_backflips = []\n",
    "        mean_losses = []\n",
    "        accuracy = []\n",
    "        self.policy.eval()\n",
    "        for f in data:\n",
    "            flips, backflips, losses, acc = self.generate_episodes(f, walksat)\n",
    "            mean_flips.append(flips)\n",
    "            mean_backflips.append(backflips)\n",
    "            if losses:\n",
    "                mean_losses.append(losses.item())\n",
    "            accuracy.append(acc)\n",
    "            mean_loss = None\n",
    "            if mean_losses:\n",
    "                mean_loss = np.mean(mean_losses)\n",
    "        print(np.mean(mean_flips), np.mean(mean_backflips), mean_loss, np.mean(accuracy))\n",
    "        \n",
    "    def train_epoch(self, optimizer, data):\n",
    "        losses = []\n",
    "        for f in data:\n",
    "            self.policy.train()\n",
    "            flips, backflips, loss, acc = self.generate_episodes(f)\n",
    "            if acc > 0:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "        print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecb0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_lr(optimizer, lr):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29037f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dir(\"../data/rand3sat/10-43\")\n",
    "#val_ds = load_dir(\"../data/rand3sat/25-106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ae3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = load_dir(\"../data/rand3sat/25-106\")\n",
    "#val_ds = load_dir(\"../data/rand3sat/25-106\")\n",
    "val_ds = train_ds[1900:]\n",
    "train_ds = train_ds[:1900]\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c035a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Net()\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "max_tries = 10\n",
    "max_flips = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293b0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_net(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d97a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.0000, -0.3289, -0.2722,  0.3029, -0.3633]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.lin2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "458dfece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = load_dir(\"../data/kcolor/4-15-0.5/\")\n",
    "train_ds = load_dir(\"../data/kcolor/3-10-0.5/\")\n",
    "val_ds = train_ds[1900:]\n",
    "train_ds = train_ds[:1900]\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de4e226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Net2()\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=0.001, weight_decay=0)\n",
    "max_tries = 10\n",
    "max_flips = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1ac45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_net2(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8104bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.,  0.,  0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#init_net(policy)\n",
    "[p for p in policy.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "decd9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tries = 10\n",
    "max_flips = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a07b4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = WalkSATLN(policy, max_tries, max_flips, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "230f7a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.36 11.426999999999998 None 1.0\n",
      "44.94 11.057999999999998 None 1.0\n",
      "46.86 11.525 None 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    ls.evaluate(val_ds, walksat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "864d5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.13 32.422999999999995 0.2566214936226606 1.0\n",
      "97.68 31.145 0.25815081529319284 1.0\n",
      "90.28 31.678999999999995 0.24032414235174657 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    ls.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21eb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.train_epoch(optimizer, train_ds[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    ls.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1484c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    ls.train_epoch(optimizer, train_ds)\n",
    "    ls.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32490a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.63 17.503999999999998 0.12857144352048636 1.0\n",
      "66.37 17.093 0.1335478150472045 1.0\n",
      "62.71 17.196 0.13198083877563477 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    ls.evaluate(val_ds)\n",
    "    evaluate(policy, val_ds, max_tries, max_flips, discount=0.5, walk_prob=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4365c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-18.3708,  -0.6255,  -0.8659]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0004], requires_grad=True)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in policy.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b133aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.99 16.944999999999997 0.14899197135120631 1.0\n",
      "59.57 16.757 0.1426751885190606 1.0\n",
      "65.47 17.554000000000002 0.14114499025046826 1.0\n"
     ]
    }
   ],
   "source": [
    "# old values\n",
    "for i in range(3):\n",
    "    evaluate(policy, val_ds, max_tries, max_flips, discount=0.5, walk_prob=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f48c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
